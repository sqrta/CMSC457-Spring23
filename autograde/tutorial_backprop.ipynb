{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n",
        "# It can be customized to whatever you like\n",
        "%matplotlib inline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quantum gradients with backpropagation\n",
        "======================================\n",
        "\n",
        "In PennyLane, any quantum device, whether a hardware device or a\n",
        "simulator, can be trained using the\n",
        "`parameter-shift rule` to compute quantum gradients. Indeed, the parameter-shift\n",
        "rule is ideally suited to hardware devices, as it does not require any\n",
        "knowledge about the internal workings of the device; it is sufficient to\n",
        "treat the device as a \\'black box\\', and to query it with different\n",
        "input values in order to determine the gradient.\n",
        "\n",
        "When working with simulators, however, we *do* have access to the\n",
        "internal (classical) computations being performed. This allows us to\n",
        "take advantage of other methods of computing the gradient, such as\n",
        "backpropagation, which may be advantageous in certain regimes. In this\n",
        "tutorial, we will compare and contrast the parameter-shift rule against\n",
        "backpropagation, using the PennyLane\n",
        "`default.qubit` device.\n",
        "\n",
        "The parameter-shift rule\n",
        "------------------------\n",
        "\n",
        "The parameter-shift rule states that, given a variational quantum\n",
        "circuit $U(\\boldsymbol\n",
        "\\theta)$ composed of parametrized Pauli rotations, and some measured\n",
        "observable $\\hat{B}$, the derivative of the expectation value\n",
        "\n",
        "$$\\langle \\hat{B} \\rangle (\\boldsymbol\\theta) =\n",
        "\\langle 0 \\vert U(\\boldsymbol\\theta)^\\dagger \\hat{B} U(\\boldsymbol\\theta) \\vert 0\\rangle$$\n",
        "\n",
        "with respect to the input circuit parameters $\\boldsymbol{\\theta}$ is\n",
        "given by\n",
        "\n",
        "$$\\nabla_{\\theta_i}\\langle \\hat{B} \\rangle(\\boldsymbol\\theta)\n",
        "   =  \\frac{1}{2}\n",
        "         \\left[\n",
        "             \\langle \\hat{B} \\rangle\\left(\\boldsymbol\\theta + \\frac{\\pi}{2}\\hat{\\mathbf{e}}_i\\right)\n",
        "           - \\langle \\hat{B} \\rangle\\left(\\boldsymbol\\theta - \\frac{\\pi}{2}\\hat{\\mathbf{e}}_i\\right)\n",
        "         \\right].$$\n",
        "\n",
        "Thus, the gradient of the expectation value can be calculated by\n",
        "evaluating the same variational quantum circuit, but with shifted\n",
        "parameter values (hence the name, parameter-shift rule!).\n",
        "\n",
        "Let\\'s have a go implementing the parameter-shift rule manually in\n",
        "PennyLane.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# set the random seed\n",
        "np.random.seed(42)\n",
        "\n",
        "# create a device to execute the circuit on\n",
        "dev = qml.device(\"default.qubit\", wires=3)\n",
        "\n",
        "@qml.qnode(dev, diff_method=\"parameter-shift\", interface=\"autograd\")\n",
        "def circuit(params):\n",
        "    qml.RX(params[0], wires=0)\n",
        "    qml.RY(params[1], wires=1)\n",
        "    qml.RZ(params[2], wires=2)\n",
        "\n",
        "    qml.broadcast(qml.CNOT, wires=[0, 1, 2], pattern=\"ring\")\n",
        "\n",
        "    qml.RX(params[3], wires=0)\n",
        "    qml.RY(params[4], wires=1)\n",
        "    qml.RZ(params[5], wires=2)\n",
        "\n",
        "    qml.broadcast(qml.CNOT, wires=[0, 1, 2], pattern=\"ring\")\n",
        "    return qml.expval(qml.PauliY(0) @ qml.PauliZ(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\\'s test the variational circuit evaluation with some parameter\n",
        "input:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters: [0.37454012 0.95071431 0.73199394 0.59865848 0.15601864 0.15599452]\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "Expectation value: -0.11971365706871565\n"
          ]
        }
      ],
      "source": [
        "# initial parameters\n",
        "params = np.random.random([6], requires_grad=True)\n",
        "\n",
        "print(\"Parameters:\", params)\n",
        "print(\"Expectation value:\", circuit(params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also draw the executed quantum circuit:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 792x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = qml.draw_mpl(circuit, decimals=2)(params)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have defined our variational circuit QNode, we can construct\n",
        "a function that computes the gradient of the $i\\text{th}$ parameter\n",
        "using the parameter-shift rule.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "-0.06518877224958126\n"
          ]
        }
      ],
      "source": [
        "def parameter_shift_term(qnode, params, i):\n",
        "    shifted = params.copy()\n",
        "    shifted[i] += np.pi/2\n",
        "    forward = qnode(shifted)  # forward evaluation\n",
        "\n",
        "    shifted[i] -= np.pi\n",
        "    backward = qnode(shifted) # backward evaluation\n",
        "\n",
        "    return 0.5 * (forward - backward)\n",
        "\n",
        "# gradient with respect to the first parameter\n",
        "print(parameter_shift_term(circuit, params, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to compute the gradient with respect to *all* parameters, we\n",
        "need to loop over the index `i`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "[-6.51887722e-02 -2.72891905e-02  0.00000000e+00 -9.33934621e-02\n",
            " -7.61067572e-01  2.77555756e-17]\n"
          ]
        }
      ],
      "source": [
        "def parameter_shift(qnode, params):\n",
        "    gradients = np.zeros([len(params)])\n",
        "\n",
        "    for i in range(len(params)):\n",
        "        gradients[i] = parameter_shift_term(qnode, params, i)\n",
        "\n",
        "    return gradients\n",
        "\n",
        "print(parameter_shift(circuit, params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compare this to PennyLane\\'s *built-in* quantum gradient support\n",
        "by using the `qml.grad <pennylane.grad>`{.interpreted-text role=\"func\"}\n",
        "function, which allows us to compute gradients of hybrid\n",
        "quantum-classical cost functions. Remember, when we defined the QNode,\n",
        "we specified that we wanted it to be differentiable using the\n",
        "parameter-shift method (`diff_method=\"parameter-shift\"`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "-0.06518877224958126\n"
          ]
        }
      ],
      "source": [
        "grad_function = qml.grad(circuit)\n",
        "print(grad_function(params)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, we can directly compute quantum gradients of QNodes using\n",
        "PennyLane\\'s built in\n",
        "`qml.gradients <pennylane.gradients>`{.interpreted-text role=\"mod\"}\n",
        "module:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "[[-6.51887722e-02 -2.72891905e-02  0.00000000e+00 -9.33934621e-02\n",
            "  -7.61067572e-01  2.77555756e-17]]\n"
          ]
        }
      ],
      "source": [
        "print(qml.gradients.param_shift(circuit)(params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you count the number of quantum evaluations, you will notice that we\n",
        "had to evaluate the circuit `2*len(params)` number of times in order to\n",
        "compute the quantum gradient with respect to all parameters. While\n",
        "reasonably fast for a small number of parameters, as the number of\n",
        "parameters in our quantum circuit grows, so does both\n",
        "\n",
        "1.  the circuit depth (and thus the time taken to evaluate each\n",
        "    expectation value or \\'forward\\' pass), and\n",
        "2.  the number of parameter-shift evaluations required.\n",
        "\n",
        "Both of these factors increase the time taken to compute the gradient\n",
        "with respect to all parameters.\n",
        "\n",
        "Benchmarking\n",
        "============\n",
        "\n",
        "Let\\'s consider an example with a significantly larger number of\n",
        "parameters. We\\'ll make use of the\n",
        "`~pennylane.StronglyEntanglingLayers`{.interpreted-text role=\"class\"}\n",
        "template to make a more complicated QNode.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "180\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "0.8947771876917632\n"
          ]
        }
      ],
      "source": [
        "dev = qml.device(\"default.qubit\", wires=4)\n",
        "\n",
        "@qml.qnode(dev, diff_method=\"parameter-shift\", interface=\"autograd\")\n",
        "def circuit(params):\n",
        "    qml.StronglyEntanglingLayers(params, wires=[0, 1, 2, 3])\n",
        "    return qml.expval(qml.PauliZ(0) @ qml.PauliZ(1) @ qml.PauliZ(2) @ qml.PauliZ(3))\n",
        "\n",
        "# initialize circuit parameters\n",
        "param_shape = qml.StronglyEntanglingLayers.shape(n_wires=4, n_layers=15)\n",
        "params = np.random.normal(scale=0.1, size=param_shape, requires_grad=True)\n",
        "print(params.size)\n",
        "print(circuit(params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This circuit has 180 parameters. Let\\'s see how long it takes to perform\n",
        "a forward pass of the circuit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "Forward pass (best of 3): 0.015673119999999586 sec per loop\n"
          ]
        }
      ],
      "source": [
        "import timeit\n",
        "\n",
        "reps = 3\n",
        "num = 10\n",
        "times = timeit.repeat(\"circuit(params)\", globals=globals(), number=num, repeat=reps)\n",
        "forward_time = min(times) / num\n",
        "\n",
        "print(f\"Forward pass (best of {reps}): {forward_time} sec per loop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now estimate the time taken to compute the full gradient vector,\n",
        "and see how this compares.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "run call\n",
            "run execute\n",
            "grad_fn <pennylane.gradients.gradient_transform.gradient_transform object at 0x000001EA292E1B80>\n",
            "Gradient computation (best of 3): 3.9554781300000004 sec per loop\n"
          ]
        }
      ],
      "source": [
        "# create the gradient function\n",
        "grad_fn = qml.grad(circuit)\n",
        "\n",
        "times = timeit.repeat(\"grad_fn(params)\", globals=globals(), number=num, repeat=reps)\n",
        "backward_time = min(times) / num\n",
        "\n",
        "print(f\"Gradient computation (best of {reps}): {backward_time} sec per loop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the parameter-shift rule, we expect that the amount of time to\n",
        "compute the quantum gradients should be approximately $2p\\Delta t_{f}$\n",
        "where $p$ is the number of parameters and $\\Delta t_{f}$ if the time\n",
        "taken for the forward pass. Let\\'s verify this:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.642323199999851\n"
          ]
        }
      ],
      "source": [
        "print(2 * forward_time * params.size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Backpropagation\n",
        "===============\n",
        "\n",
        "An alternative to the parameter-shift rule for computing gradients is\n",
        "[reverse-mode\n",
        "autodifferentiation](https://en.wikipedia.org/wiki/Reverse_accumulation).\n",
        "Unlike the parameter-shift method, which requires $2p$ circuit\n",
        "evaluations for $p$ parameters, reverse-mode requires only a *single*\n",
        "forward pass of the differentiable function to compute the gradient of\n",
        "all variables, at the expense of increased memory usage. During the\n",
        "forward pass, the results of all intermediate subexpressions are stored;\n",
        "the computation is then traversed *in reverse*, with the gradient\n",
        "computed by repeatedly applying the chain rule. In most classical\n",
        "machine learning settings (where we are training scalar loss functions\n",
        "consisting of a large number of parameters), reverse-mode\n",
        "autodifferentiation is the preferred method of\n",
        "autodifferentiation\\-\\--the reduction in computational time enables\n",
        "larger and more complex models to be successfully trained. The\n",
        "backpropagation algorithm is a particular special-case of reverse-mode\n",
        "autodifferentiation, which has helped lead to the machine learning\n",
        "explosion we see today.\n",
        "\n",
        "In quantum machine learning, however, the inability to store and utilize\n",
        "the results of *intermediate* quantum operations on hardware remains a\n",
        "barrier to using backprop; while reverse-mode autodifferentiation works\n",
        "fine for small quantum simulations, only the parameter-shift rule can be\n",
        "used to compute gradients on quantum hardware directly. Nevertheless,\n",
        "when training quantum models via classical simulation, it\\'s useful to\n",
        "explore the regimes where reverse-mode differentiation may be a better\n",
        "choice than the parameter-shift rule.\n",
        "\n",
        "Benchmarking\n",
        "------------\n",
        "\n",
        "When creating a QNode,\n",
        "`PennyLane supports various methods of differentiation\n",
        "<code/api/pennylane.qnode>`{.interpreted-text role=\"doc\"}, including\n",
        "`\"parameter-shift\"` (which we used previously), `\"finite-diff\"`,\n",
        "`\"reversible\"`, and `\"backprop\"`. While `\"parameter-shift\"` works with\n",
        "all devices (simulator or hardware), `\"backprop\"` will only work for\n",
        "specific simulator devices that are designed to support backpropagation.\n",
        "\n",
        "One such device is\n",
        "`default.qubit <pennylane.devices.DefaultQubit>`{.interpreted-text\n",
        "role=\"class\"}. It has backends written using TensorFlow, JAX, and\n",
        "Autograd, so when used with the TensorFlow, JAX, and Autograd interfaces\n",
        "respectively, supports backpropagation. In this demo, we will use the\n",
        "default Autograd interface.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev = qml.device(\"default.qubit\", wires=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When defining the QNode, we specify `diff_method=\"backprop\"` to ensure\n",
        "that we are using backpropagation mode. Note that this is the *default\n",
        "differentiation mode* for the `default.qubit` device.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "0.9358535378025427\n"
          ]
        }
      ],
      "source": [
        "@qml.qnode(dev, diff_method=\"backprop\", interface=\"autograd\")\n",
        "def circuit(params):\n",
        "    qml.StronglyEntanglingLayers(params, wires=[0, 1, 2, 3])\n",
        "    return qml.expval(qml.PauliZ(0) @ qml.PauliZ(1) @ qml.PauliZ(2) @ qml.PauliZ(3))\n",
        "\n",
        "# initialize circuit parameters\n",
        "param_shape = qml.StronglyEntanglingLayers.shape(n_wires=4, n_layers=15)\n",
        "params = np.random.normal(scale=0.1, size=param_shape, requires_grad=True)\n",
        "print(circuit(params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\\'s see how long it takes to perform a forward pass of the circuit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "run call\n",
            "run execute\n",
            "grad_fn backprop\n",
            "Forward pass (best of 3): 0.038963920000000485 sec per loop\n"
          ]
        }
      ],
      "source": [
        "import timeit\n",
        "\n",
        "reps = 3\n",
        "num = 10\n",
        "times = timeit.repeat(\"circuit(params)\", globals=globals(), number=num, repeat=reps)\n",
        "forward_time = min(times) / num\n",
        "print(f\"Forward pass (best of {reps}): {forward_time} sec per loop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comparing this to the forward pass from `default.qubit`, we note that\n",
        "there is some potential overhead from using backpropagation. We can now\n",
        "estimate the time required to perform a gradient computation via\n",
        "backpropagation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "times = timeit.repeat(\"qml.grad(circuit)(params)\", globals=globals(), number=num, repeat=reps)\n",
        "backward_time = min(times) / num\n",
        "print(f\"Backward pass (best of {reps}): {backward_time} sec per loop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unlike with the parameter-shift rule, the time taken to perform the\n",
        "backwards pass appears of the order of a single forward pass! This can\n",
        "significantly speed up training of simulated circuits with many\n",
        "parameters.\n",
        "\n",
        "Time comparison\n",
        "===============\n",
        "\n",
        "Let\\'s compare the two differentiation approaches as the number of\n",
        "trainable parameters in the variational circuit increases, by timing\n",
        "both the forward pass and the gradient computation as the number of\n",
        "layers is allowed to increase.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev = qml.device(\"default.qubit\", wires=4)\n",
        "\n",
        "def circuit(params):\n",
        "    qml.StronglyEntanglingLayers(params, wires=[0, 1, 2, 3])\n",
        "    return qml.expval(qml.PauliZ(0) @ qml.PauliZ(1) @ qml.PauliZ(2) @ qml.PauliZ(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We\\'ll continue to use the same ansatz as before, but to reduce the time\n",
        "taken to collect the data, we\\'ll reduce the number and repetitions of\n",
        "timings per data point. Below, we loop over a variational circuit depth\n",
        "ranging from 0 (no gates/ trainable parameters) to 20. Each layer will\n",
        "contain $3N$ parameters, where $N$ is the number of wires (in this case,\n",
        "we have $N=4$).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reps = 2\n",
        "num = 3\n",
        "\n",
        "forward_shift = []\n",
        "gradient_shift = []\n",
        "forward_backprop = []\n",
        "gradient_backprop = []\n",
        "\n",
        "for depth in range(0, 21):\n",
        "    param_shape = qml.StronglyEntanglingLayers.shape(n_wires=4, n_layers=depth)\n",
        "    params = np.random.normal(scale=0.1, size=param_shape, requires_grad=True)\n",
        "    num_params = params.size\n",
        "\n",
        "    # forward pass timing\n",
        "    # ===================\n",
        "\n",
        "    qnode_shift = qml.QNode(circuit, dev, diff_method=\"parameter-shift\", interface=\"autograd\")\n",
        "    qnode_backprop = qml.QNode(circuit, dev, diff_method=\"backprop\", interface=\"autograd\")\n",
        "\n",
        "    # parameter-shift\n",
        "    t = timeit.repeat(\"qnode_shift(params)\", globals=globals(), number=num, repeat=reps)\n",
        "    forward_shift.append([num_params, min(t) / num])\n",
        "\n",
        "    # backprop\n",
        "    t = timeit.repeat(\"qnode_backprop(params)\", globals=globals(), number=num, repeat=reps)\n",
        "    forward_backprop.append([num_params, min(t) / num])\n",
        "\n",
        "    if num_params == 0:\n",
        "        continue\n",
        "\n",
        "    # Gradient timing\n",
        "    # ===============\n",
        "\n",
        "    qnode_shift = qml.QNode(circuit, dev, diff_method=\"parameter-shift\", interface=\"autograd\")\n",
        "    qnode_backprop = qml.QNode(circuit, dev, diff_method=\"backprop\", interface=\"autograd\")\n",
        "\n",
        "    # parameter-shift\n",
        "    t = timeit.repeat(\"qml.grad(qnode_shift)(params)\", globals=globals(), number=num, repeat=reps)\n",
        "    gradient_shift.append([num_params, min(t) / num])\n",
        "\n",
        "    # backprop\n",
        "    t = timeit.repeat(\"qml.grad(qnode_backprop)(params)\", globals=globals(), number=num, repeat=reps)\n",
        "    gradient_backprop.append([num_params, min(t) / num])\n",
        "\n",
        "gradient_shift = np.array(gradient_shift).T\n",
        "gradient_backprop = np.array(gradient_backprop).T\n",
        "forward_shift = np.array(forward_shift).T\n",
        "forward_backprop = np.array(forward_backprop).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now import matplotlib, and plot the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.style.use(\"bmh\")\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "\n",
        "ax.plot(*gradient_shift, '.-', label=\"Parameter-shift\")\n",
        "ax.plot(*gradient_backprop, '.-', label=\"Backprop\")\n",
        "ax.set_ylabel(\"Time (s)\")\n",
        "ax.set_xlabel(\"Number of parameters\")\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{=html}\n",
        "<br>\n",
        "```\n",
        "We can see that the computational time for the parameter-shift rule\n",
        "increases with increasing number of parameters, as expected, whereas the\n",
        "computational time for backpropagation appears much more constant, with\n",
        "perhaps a minute linear increase with $p$. Note that the plots are not\n",
        "perfectly linear, with some \\'bumpiness\\' or noisiness. This is likely\n",
        "due to low-level operating system jitter, and other environmental\n",
        "fluctuations\\-\\--increasing the number of repeats can help smooth out\n",
        "the plot.\n",
        "\n",
        "For a better comparison, we can scale the time required for computing\n",
        "the quantum gradients against the time taken for the corresponding\n",
        "forward pass:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gradient_shift[1] /= forward_shift[1, 1:]\n",
        "gradient_backprop[1] /= forward_backprop[1, 1:]\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "\n",
        "ax.plot(*gradient_shift, '.-', label=\"Parameter-shift\")\n",
        "ax.plot(*gradient_backprop, '.-', label=\"Backprop\")\n",
        "\n",
        "# perform a least squares regression to determine the linear best fit/gradient\n",
        "# for the normalized time vs. number of parameters\n",
        "x = gradient_shift[0]\n",
        "m_shift, c_shift = np.polyfit(*gradient_shift, deg=1)\n",
        "m_back, c_back = np.polyfit(*gradient_backprop, deg=1)\n",
        "\n",
        "ax.plot(x, m_shift * x + c_shift, '--', label=f\"{m_shift:.2f}p{c_shift:+.2f}\")\n",
        "ax.plot(x, m_back * x + c_back, '--', label=f\"{m_back:.2f}p{c_back:+.2f}\")\n",
        "\n",
        "ax.set_ylabel(\"Normalized time\")\n",
        "ax.set_xlabel(\"Number of parameters\")\n",
        "ax.set_xscale(\"log\")\n",
        "ax.set_yscale(\"log\")\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{=html}\n",
        "<br>\n",
        "```\n",
        "We can now see clearly that there is constant overhead for\n",
        "backpropagation with `default.qubit`, but the parameter-shift rule\n",
        "scales as $\\sim 2p$.\n",
        "\n",
        "About the author\n",
        "================\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
